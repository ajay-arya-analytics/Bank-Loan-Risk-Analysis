{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080cdc7-24f8-40da-9ae0-ba380a2615bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a968b-40c4-4fff-a912-4ff008e4daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only load these specific columns to save memory\n",
    "COLS_TO_USE = [\n",
    "    'id', 'loan_amnt', 'term', 'int_rate', 'grade', 'sub_grade',\n",
    "    'emp_length', 'home_ownership', 'annual_inc', 'verification_status',\n",
    "    'issue_d', 'loan_status', 'purpose', 'addr_state', 'dti', \n",
    "    'installment', 'total_pymnt', 'total_rec_prncp', 'total_rec_int']\n",
    "\n",
    "print(\"‚è≥ Loading data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8afe2de-2e91-429b-85d0-cd126002e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with low_memory=False to handle mixed types\n",
    "df = pd.read_csv('loan.csv', usecols=COLS_TO_USE, low_memory=False)\n",
    "\n",
    "print(f\"‚úÖ Data Loaded! Total Rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3061e4e-06c1-42d5-8b57-b5a886735041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903602e-f45e-461c-bb0b-95d9b1c81f22",
   "metadata": {},
   "source": [
    "# --- DATA CLEANING STEPS --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d1077-be5c-4ee7-806f-3f7787767630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "# For binary risk analysis we only want 'Fully Paid' and 'Charged Off' \n",
    "df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off', 'Current'])]\n",
    "print(f\"   Rows after filtering status: {len(df)}\")\n",
    "\n",
    "# 2.\n",
    "# Convert Date Column\n",
    "df['issue_date'] = pd.to_datetime(df['issue_d'], format='%b-%Y')\n",
    "df.drop(columns=['issue_d'], inplace=True) # Remove original column\n",
    "\n",
    "# 3.\n",
    "# Removing 'months' string (Example: \" 36 months\" -> 36)\n",
    "df['term'] = df['term'].astype(str).str.replace(' months', '').str.strip().astype(int)\n",
    "\n",
    "# 4.\n",
    "# Extracting numbers from 'Emp Length' (Example: \"10+ years\" -> 10, \"< 1 year\" -> 0)\n",
    "# We use regex to find the first number in the string\n",
    "df['emp_length_clean'] = df['emp_length'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
    "df['emp_length_clean'].fillna(0, inplace=True) # Assume 0 if missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da1eff-2834-4d74-855b-530866aa491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Handling Missing Values\n",
    "# Filling missing annual income with the median (safer than average)\n",
    "df['annual_inc'].fillna(df['annual_inc'].median(), inplace=True)\n",
    "\n",
    "\n",
    "# 6. Outlier Removal\n",
    "# Removing annual incomes > top 99% (e.g., millionaires skewing the data)\n",
    "q_high = df['annual_inc'].quantile(0.99)\n",
    "df = df[df['annual_inc'] < q_high]\n",
    "\n",
    "\n",
    "# 7. Creating 'Income Category'\n",
    "# creating a new categorical column\n",
    "conditions = [\n",
    "    (df['annual_inc'] < 40000),\n",
    "    (df['annual_inc'] >= 40000) & (df['annual_inc'] < 80000),\n",
    "    (df['annual_inc'] >= 80000)\n",
    "]\n",
    "choices = ['Low Income', 'Middle Income', 'High Income']\n",
    "df['income_category'] = np.select(conditions, choices, default='Unknown')\n",
    "\n",
    "\n",
    "# 8. Creating 'Interest Rate Bucket'\n",
    "# Allows to see if high-interest loans default more\n",
    "conditions_int = [\n",
    "    (df['int_rate'] < 10),\n",
    "    (df['int_rate'] >= 10) & (df['int_rate'] < 15),\n",
    "    (df['int_rate'] >= 15)\n",
    "]\n",
    "choices_int = ['Low Rate (<10%)', 'Medium Rate (10-15%)', 'High Rate (>15%)']\n",
    "df['int_rate_bucket'] = np.select(conditions_int, choices_int, default='Unknown')\n",
    "\n",
    "\n",
    "print(f\"   Final Rows after cleaning: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a70f0-8284-4886-abc4-e4cac501f852",
   "metadata": {},
   "source": [
    "# --- EXPORT ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2675ab-a424-4f7b-9849-d91850cf8553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('bank_loan.csv', index=False)\n",
    "print(f\"üéâ Success! Cleaned file saved as: {'bank_loan.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f97c9e-a3c9-45a5-b666-1e0eeef6d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sqlalchemy pymysql\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8cb24b-9206-4bb0-ae94-4c85020c37dd",
   "metadata": {},
   "source": [
    "# --- CONFIGURATION ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1ef290-13e7-465b-bad6-9d16b995c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This encodes the password to handle special characters (like '@') safely\n",
    "encoded_password = quote_plus(DB_PASSWORD)\n",
    "\n",
    "CSV_FILE = 'bank_loan.csv'\n",
    "DB_USER = 'root'\n",
    "DB_PASSWORD = 'PASSWORD' \n",
    "DB_HOST = 'localhost'\n",
    "DB_NAME = 'bank_loan_db'    \n",
    "\n",
    "\n",
    "# 1. Read the Cleaned CSV\n",
    "print(\"‚è≥ Reading CSV file...\")\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "\n",
    "# 2. Create the Database Connection\n",
    "# format: mysql+pymysql://username:password@host/database_name\n",
    "connection_str = f\"mysql+pymysql://{DB_USER}:{encoded_password}@{DB_HOST}/{DB_NAME}\"\n",
    "engine = create_engine(connection_str)\n",
    "\n",
    "\n",
    "# 3. Load Data to MySQL\n",
    "print(\"‚è≥ Uploading to MySQL... (This might take a minute)\")\n",
    "\n",
    "# 'chunksize' splits the upload into smaller parts to avoid timeout errors\n",
    "df.to_sql('bank_loan_data', con=engine, index=False, if_exists='replace', chunksize=1000)\n",
    "\n",
    "print(\"üéâ Success! Data is now in the 'bank_loan_data' table.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
